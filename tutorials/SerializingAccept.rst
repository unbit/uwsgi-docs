Serializing accept(), AKA Thundering Herd, AKA the Zeeg Problem
===============================================================

One of the hystorical problems in the UNIX world is the "thundering herd".

What is it ?

Take a process binding to a networking address (it could be AF_INET, AF_UNIX or whatever you want) and then forking itself:

.. code-block:: c

   int s = socket(...)
   bind(s, ...)
   listen(s, ...)
   fork()
   
after having forked itself a bunch of times, each of the process will generally start blocking on accept()

.. code-block:: c

   for(;;) {
       int client = accept(...);
       if (client < 0) continue;
       ...
   }
   
The funny problem is that on older/classic UNIX, accept() is woke up in each process blocked on it.

That means a vast amount of wasted cpu cycles (the kernel scheduler has to give control to all of the sleeping processes waiting on that socket)

This behaviour (for various reasons) is amplified when instead of processes you use threads (so, you have multiple threads blocked on accept())

The "de-facto" soluction was placing a lock before the accept() call to serialize its usage:

.. code-block:: c

   for(;;) {
       lock();
       int client = accept(...);
       unlock();
       if (client < 0) continue;
       ...
   }
   
For threads dealing with locks is generally easier, but for processes you have to fight with system-specific solutions or fallback to the venerable SysV ipc
subsystem (more on this later)

In modern times, the vast majority of UNIX systems have evolved, and now the kernel ensure (more or less) only one process/thread is woke up on a connection event.

Ok, problem solved, what we are talking abut ?

select()/poll()/kqueue()/epoll()/...
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In the pre-1.0 era, uWSGI was a lot simpler (and less interesting) than the current form. It did not have the signal framework and it was not able to listen to multiple addresses, for this reason
its loop engine was only calling accept() in each process/thread, and thundering herd (thanks to modern kernels) was not a problem.

Evolution has a price, so after a bit the standard loop engine of a uWSGI process/thread moved from:

.. code-block:: c

   for(;;) {
       int client = accept(s, ...);
       if (client < 0) continue;
       ...
   }
   
to a more "complex":

.. code-block:: c

   for(;;) {
       int interesting_fd = wait_for_fds();
       if (fd_need_accept(interesting_fd)) {
           int client = accept(interesting_fd, ...);
           if (client < 0) continue;
       }
       else if (fd_is_a_signal(interesting_fd)) {
           manage_uwsgi_signal(interesting_fd);
       }
       ...
   }
   
The problem is now the wait_for_fds() example function: it will call something like select(), poll() or the more modern epoll() and kqueue()

This kind of system calls are "monitors" for file descriptors, and they are woke up in all of the processes/threads waiting for the same file descriptor.

Before you start blaming your kernel developers, this is the right approach, as the kernel cannot knows if you are waiting for those file descriptors to call accept() or to make something funnier.

So, welcome again to the thundering herd.

Application Servers VS WebServers
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The popular, battle tested, solid, multiprocess reference webserver is for sure Apache HTTPD.

It survived decades of IT evolutions and its still one of the most important technologies powering the whole Internet.

Born as multiprocess-only, apache had to always deal with the thundering herd problem and they solved it using SysV ipc semaphores.

Even on modern Apache releases, stracing one of its process you will see something like that (it is a Linux system):

.. code-block:: c

   semop(...); // lock
   epoll_wait(...);
   accept(...);
   semop(...); // unlock
   ... // manage the request
   
the SysV semaphore protect your epoll_wait from thundering herd.

So, another problem solved, the world is a such a beatiful place... but ....

```SysV IPC is not good for application servers :(```

The definition of "application server" is pretty generic, in this case we refer to one or more process/processes generated by an unprivileged (non-root) user
binding on one ore more network address and running custom, highly undeterministic code.

Even if you had a minimal/basic knowledge on how SysV IPC works, you will know each of its component is a limited resource in the system
(and in moderns BSDs this limits are set to ridicolously low values, PostgreSQL FreeBSD users know this problem very well).

Just run 'ipcs' in your terminal to get a list of the allocated objects in your kernel. Yes, in your kernel. SysV ipc objects are persistent resources, they need
to be removed manually by the user. The same user that could allocate hundreds of those objects and fill your limited SysV IPC memory.

One of the most common problems in the apache world caused by the SysV ipc usage is the mod_rewrite leakage when you brutally kills apache instances
(yes, you should never do it, but you have not much choices if you are so brave/fool to host unreliable php apps in your webserver process)

Apache is generally a system service, managed by a consciuos sysadmin, so except few cases you can continue trusting it for more decades, even if it decides to use more SysV ipc objects :)

Your application server, sadly, is managed by different kind of users, from the most skilled one, to the one who should change job as soon as possibile to the one with the site cracked by a moron wanting to
take control of your server.

Application servers are not dangerous, users are. And application servers are run by users. The world is an ugly place.

How application server developers solved it
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fast answer: they generally does not solve/care it

Serving static files or proxying (the main activities of a webserver) is generaly a fast, non-blocking (very deterministic under various points of view) activity. Instead a webapplication
is way slower and havier, so,  even on moderately loaded sites, the amount of sleeping processes is generally low.

On higly loaded sites you will pray for a free process, and in non-loaded sites the thundering herd problem is completely irrelevant (unless you are running
your site on a 386)

Given the relatively low number of processes you generally allocate for an application server, we can say thundering herd is a no-problem

Another approach is dynamic process spawning. If you ensure your application server has always the minimum required number of processes running
you will highly reduce the thundering herd problem.

No-problem ??? So, again, what we are talking about ?
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We are talking about "common cases", and for common cases there a plethora of valid choices (instead of uWSGI, obviously) and the vast majrity of problems
are non-existent. 

Since the beginning of the uWSGI project, being developed by an hosting company where "common cases" do not exist, we cared a lot
corner-case problems, bizarre setups and those problems the vast majority of users never need to care about.

In addition to this, uWSGI supports operational modes other application servers




